{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "from bs4 import BeautifulSoup as BS, SoupStrainer as SS\n",
    "import urllib2\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "from lxml.html.clean import Cleaner\n",
    "import re\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scrapy import Item, Field\n",
    "from scrapy.loader import ItemLoader\n",
    "from scrapy.loader.processors import TakeFirst, Identity\n",
    "\n",
    "\n",
    "class Detail(Item):\n",
    "    detail_url = Field()\n",
    "    name = Field()\n",
    "    address = Field()\n",
    "    url = Field()\n",
    "    about = Field()\n",
    "\n",
    "class DetailLoader(ItemLoader):\n",
    "    default_output_processor = TakeFirst()\n",
    "    address_out = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\lux-python\\scrappy-scrapin\\ces2017\\ces2017\n"
     ]
    }
   ],
   "source": [
    "cd ces2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\n",
      "__init__.pyc\n",
      "items.py\n",
      "items.pyc\n",
      "middlewares.py\n",
      "pipelines.py\n",
      "settings.py\n",
      "settings.pyc\n",
      "spiders\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from selenium import webdriver\n",
    "# from ces2017.items import Detail, DetailLoader\n",
    "\n",
    "def safe_strip(x):\n",
    "    return x if x is None else x.strip()\n",
    "\n",
    "class CesSpider(scrapy.Spider):\n",
    "    name = 'ces'\n",
    "\n",
    "    download_delay = 1\n",
    "\n",
    "    def __init__(self):\n",
    "        self.browser = webdriver.PhantomJS()\n",
    "        self.start = 'http://ces17.mapyourshow.com/7_0/alphalist.cfm?alpha=*'\n",
    "        self.items = []\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(self.start, callback=self.parse_start)\n",
    "\n",
    "    def parse_start(self, response):\n",
    "        self.browser.get(response.url)\n",
    "        items = self.browser.find_elements_by_css_selector('td.mys-table-exhname a')\n",
    "\n",
    "        while len(items) > len(self.items):\n",
    "            for item in items:\n",
    "                detail_url = item.get_attribute('href')\n",
    "                yield scrapy.Request(detail_url, callback=self.parse_detail)\n",
    "\n",
    "            self.items = items\n",
    "\n",
    "            # scroll down and update list of items\n",
    "            self.browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            items = self.browser.find_elements_by_css_selector('td.mys-table-exhname a')\n",
    "            print '>>>>> scrolling: {} --> {}'.format(len(self.items), len(items))\n",
    "\n",
    "        self.browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-16 11:29:26 [scrapy] INFO: Scrapy 1.2.2 started (bot: ces2017)\n",
      "2016-12-16 11:29:26 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'ces2017.spiders', 'FEED_URI': 'out.json', 'SPIDER_MODULES': ['ces2017.spiders'], 'BOT_NAME': 'ces2017', 'ROBOTSTXT_OBEY': True, 'FEED_FORMAT': 'json'}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\anaconda2\\lib\\runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"c:\\anaconda2\\lib\\runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"C:\\Anaconda2\\Scripts\\scrapy.exe\\__main__.py\", line 9, in <module>\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\cmdline.py\", line 142, in execute\n",
      "    _run_print_help(parser, _run_command, cmd, args, opts)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\cmdline.py\", line 88, in _run_print_help\n",
      "    func(*a, **kw)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\cmdline.py\", line 149, in _run_command\n",
      "    cmd.run(args, opts)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\commands\\crawl.py\", line 57, in run\n",
      "    self.crawler_process.crawl(spname, **opts.spargs)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\crawler.py\", line 162, in crawl\n",
      "    crawler = self.create_crawler(crawler_or_spidercls)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\crawler.py\", line 190, in create_crawler\n",
      "    return self._create_crawler(crawler_or_spidercls)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\crawler.py\", line 194, in _create_crawler\n",
      "    spidercls = self.spider_loader.load(spidercls)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\scrapy\\spiderloader.py\", line 43, in load\n",
      "    raise KeyError(\"Spider not found: {}\".format(spider_name))\n",
      "KeyError: 'Spider not found: ces2017'\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl ces2017 -o out.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
